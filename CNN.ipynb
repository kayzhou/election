{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量化（vectorize）\n",
    "\n",
    "from my_weapon import *\n",
    "from gensim.models import Word2Vec\n",
    "import word2vecReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.425314e+06\n",
      "mean     1.650435e+01\n",
      "std      5.510423e+00\n",
      "min      1.000000e+00\n",
      "25%      1.300000e+01\n",
      "50%      1.700000e+01\n",
      "75%      2.000000e+01\n",
      "max      1.110000e+02\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 统计最长的序列\n",
    "\n",
    "d = pd.Series([len(line.strip().split(\" \")) for line in open(\"data/train.txt\")])\n",
    "print(d.describe())\n",
    "d.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2Vec.load(\"model/word2vec.mod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最长的序列是111个tokens，我决定用40作为每个句子的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update vectorize\n",
    "# 需要经过tweet_process.py的处理\n",
    "\n",
    "def vectorize(line):\n",
    "    v = np.zeros(40 * 400).reshape(40, 400)\n",
    "    words = line.strip().split(\" \")\n",
    "    _index = 0\n",
    "    for w in words:\n",
    "        if _index >= 40:\n",
    "            break\n",
    "        if w in wv_model.wv:\n",
    "            v[_index] = wv_model.wv[w]\n",
    "            _index += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.08587575,  0.41580471, -2.2741425 , ..., -0.0125636 ,\n",
       "         2.06250668,  0.08311198],\n",
       "       [-0.81667441,  0.94962615, -1.45155382, ...,  0.22324868,\n",
       "         1.16281199, -0.71577537],\n",
       "       [-0.68626755,  0.78144592, -2.61305523, ...,  0.71367294,\n",
       "         0.76811117,  2.10258842],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(\"what are you doing ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们看看另外一个已经训练好的在大的数据集上的word2vec model\n",
    "\n",
    "location: /media/alex/data/word2vec_twitter_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\tword2vecReader.py  word2vecReaderUtils.py  word2vec_twitter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls /media/alex/data/word2vec_twitter_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This zip contains a word2vec model trained on Twitter data as described in:\n",
      "\n",
      "Godin, F., Vandersmissen, B., De Neve, W., & Van de Walle, R. (2015).\n",
      "Multimedia Lab @ ACL W-NUT NER shared task: Named entity recognition for Twitter microposts using distributed word representations.\n",
      "Workshop on Noisy User-generated Text, ACL 2015.\n",
      "\n",
      "Please cite the paper if you use the model.\n",
      "\n",
      "This zip contains 2 additional files to read the word2vec model with Python.\n",
      "The code for this was extracted from the Gensim Library which can be found here: https://radimrehurek.com/gensim/models/word2vec.html\n",
      "The only difference is that it does not use a strict encoding to read the model from the file.\n",
      "(One can easily integrate, inherit or extend the library or the Python files)"
     ]
    }
   ],
   "source": [
    "!cat /media/alex/data/word2vec_twitter_model/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wv_model2 = word2vecReader.Word2Vec.load_word2vec_format(\"/media/alex/data/word2vec_twitter_model/word2vec_twitter_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model2[\"love\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_2(line):\n",
    "    v = np.zeros(40 * 400).reshape(40, 400)\n",
    "    words = line.strip().split(\" \")\n",
    "    _index = 0\n",
    "    for w in words:\n",
    "        if _index >= 40:\n",
    "            break\n",
    "        if w in wv_model2:\n",
    "            v[_index] = wv_model2[w]\n",
    "            _index += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03832966,  0.00200333, -0.04462779, ...,  0.0044597 ,\n",
       "         0.02114136, -0.02238772],\n",
       "       [ 0.04128342,  0.07181156,  0.00676483, ..., -0.00052616,\n",
       "         0.01673744,  0.01691386],\n",
       "       [-0.01901733,  0.00757742,  0.00171131, ...,  0.05948232,\n",
       "         0.0217214 , -0.00660098],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_2(\"i love you so much\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([10, 64, 38, 1])\n",
      "relu: torch.Size([10, 64, 38, 1])\n",
      "squeeze: torch.Size([10, 64, 38])\n",
      "max_pool1d: torch.Size([10, 64, 19])\n",
      "flat: torch.Size([10, 1216])\n",
      "f1: torch.Size([10, 64])\n",
      "f2: torch.Size([10, 32])\n",
      "f3: torch.Size([10, 1])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# batch=10, in_channels=2, height(num of tokens)=20, width(length of word2vec)=400\n",
    "_in = torch.randn(10, 2, 40, 400)\n",
    "\n",
    "\n",
    "# in_channels=2, out_channels=32, kernel_size=(3, 400)\n",
    "tmp_mod = torch.nn.Conv2d(2, 64, kernel_size=(3, 400), groups=2)\n",
    "\n",
    "_out = tmp_mod(_in)\n",
    "print(\"conv1:\", _out.size())\n",
    "\n",
    "_out = F.relu(_out)\n",
    "print(\"relu:\", _out.size())\n",
    "\n",
    "_out = torch.squeeze(_out)\n",
    "print(\"squeeze:\", _out.size())\n",
    "\n",
    "_out = F.max_pool1d(_out, 2)\n",
    "print(\"max_pool1d:\", _out.size())\n",
    "\n",
    "_out = _out.view(-1, 2 * 32 * 19)\n",
    "print(\"flat:\", _out.size())\n",
    "\n",
    "f1 = nn.Linear(1216, 64)\n",
    "_out = f1(_out)\n",
    "_out = F.relu(_out)\n",
    "print(\"f1:\", _out.size())\n",
    "\n",
    "f2 = nn.Linear(64, 32)\n",
    "_out = f2(_out)\n",
    "_out = F.relu(_out)\n",
    "print(\"f2:\", _out.size())\n",
    "\n",
    "f3 = nn.Linear(32, 1)\n",
    "_out = f3(_out)\n",
    "# _out = F.relu(_out)\n",
    "print(\"f3:\", _out.size())\n",
    "\n",
    "probs = F.softmax(_out, 1)\n",
    "print(probs)\n",
    "torch.max(probs, 1)[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_in = torch.randn(10, 2, 40, 400)\n",
    "model = CNNClassifier()\n",
    "model(_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train dataset\n",
    "\n",
    "import random\n",
    "\n",
    "with open(\"data/train_dataset.txt\", \"w\") as f:\n",
    "    lines = []\n",
    "    for line in open(\"data/0-train.txt\"):\n",
    "        lines.append(\"0\\t{}\".format(line))\n",
    "    for line in open(\"data/1-train.txt\"):\n",
    "        lines.append(\"1\\t{}\".format(line))\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.train_file = \"data/train_dataset.txt\"\n",
    "        self.train_batch_size = 128\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        self.window_size = 3\n",
    "        self.num_classes = 2\n",
    "        \n",
    "        self.num_epochs = 10\n",
    "        self.train_steps = None\n",
    "        \n",
    "        self.summary_interval = 100\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10 条信息，2 Input，40 词，每个词400向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2018-11-26 14:35:58,028\tloading Word2Vec object from model/word2vec.mod\n",
      "INFO\t2018-11-26 14:35:58,526\tloading wv recursively from model/word2vec.mod.wv.* with mmap=None\n",
      "INFO\t2018-11-26 14:35:58,526\tloading vectors from model/word2vec.mod.wv.vectors.npy with mmap=None\n",
      "INFO\t2018-11-26 14:36:00,030\tsetting ignored attribute vectors_norm to None\n",
      "INFO\t2018-11-26 14:36:00,030\tloading vocabulary recursively from model/word2vec.mod.vocabulary.* with mmap=None\n",
      "INFO\t2018-11-26 14:36:00,031\tloading trainables recursively from model/word2vec.mod.trainables.* with mmap=None\n",
      "INFO\t2018-11-26 14:36:00,031\tloading syn1neg from model/word2vec.mod.trainables.syn1neg.npy with mmap=None\n",
      "INFO\t2018-11-26 14:36:01,525\tsetting ignored attribute cum_table to None\n",
      "INFO\t2018-11-26 14:36:01,526\tloaded model/word2vec.mod\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, filepath, batch_size):\n",
    "        self._file = open(filepath)\n",
    "        self._wv1 = self.read_wv1()\n",
    "        self._wv2 = self.read_wv2()\n",
    "        self._batch_size = batch_size\n",
    "        self._reset()\n",
    "\n",
    "    def read_wv1(self):\n",
    "        return Word2Vec.load(\"model/word2vec.mod\")\n",
    "        \n",
    "    def read_wv2(self):\n",
    "        return word2vecReader.Word2Vec.load_word2vec_format(\n",
    "            \"/media/alex/data/word2vec_twitter_model/word2vec_twitter_model.bin\", binary=True)\n",
    "\n",
    "    def wv1(self, line):\n",
    "        v = np.zeros(40 * 400).reshape(40, 400)\n",
    "        words = line.strip().split(\" \")\n",
    "        _index = 0\n",
    "        for w in words:\n",
    "            if _index >= 40:\n",
    "                break\n",
    "            if w in self._wv1.wv:\n",
    "                v[_index] = self._wv1.wv[w]\n",
    "                _index += 1\n",
    "        return v\n",
    "\n",
    "    def wv2(self, line):\n",
    "            v = np.zeros(40 * 400).reshape(40, 400)\n",
    "            words = line.strip().split(\" \")\n",
    "            _index = 0\n",
    "            for w in words:\n",
    "                if _index >= 40:\n",
    "                    break\n",
    "                if w in self._wv2:\n",
    "                    v[_index] = self._wv2[w]\n",
    "                    _index += 1\n",
    "            return v\n",
    "\n",
    "    def _fill_buffer(self, size):\n",
    "        if not self._buffer:\n",
    "            for line in self._file:\n",
    "                label, sentence = line.split(\"\\t\")\n",
    "                label = int(label.strip())\n",
    "                sequence1 = self.wv1(sentence)\n",
    "                sequence2 = self.wv2(sentence)\n",
    "                self._buffer.append((label, [sequence1, sequence2]))\n",
    "                if len(self._buffer) >= size:\n",
    "                    break\n",
    "            self._buffer_iter = iter(self._buffer)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._reset()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self._fill_buffer(self._batch_size * 1000)\n",
    "\n",
    "        label_batch = []\n",
    "        sequence_batch = []\n",
    "        for label, sequence in self._buffer_iter:\n",
    "            label_batch.append(label)\n",
    "            sequence_batch.append(sequence)\n",
    "            if len(label_batch) == self._batch_size:\n",
    "                break\n",
    "\n",
    "        if not label_batch:\n",
    "            raise StopIteration\n",
    "\n",
    "        return {\"sequences\": np.array(sequence_batch), \"labels\": label_batch, }\n",
    "\n",
    "    def _reset(self):\n",
    "        self._file.seek(0)\n",
    "        self._buffer = []\n",
    "        self._buffer_iter = None\n",
    "\n",
    "train_set = Dataset(config.train_file, config.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2, 40, 400)\n"
     ]
    }
   ],
   "source": [
    "for tmp in train_set:\n",
    "    print(tmp[\"sequences\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd, optim, nn\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        # 2 in- channels, 32 out- channels, 3 * 400 windows size\n",
    "        self.conv = torch.nn.Conv2d(2, 64, kernel_size=(3, 400), groups=2) \n",
    "        self.f1 = nn.Linear(1216, 64)\n",
    "        self.f2 = nn.Linear(64, 32)\n",
    "        self.f3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = F.relu(out)\n",
    "        out = torch.squeeze(out)\n",
    "        out = F.max_pool1d(out, 2)\n",
    "        out = out.view(-1, 2 * 32 * 19) # 9 is after pooling\n",
    "        out = F.relu(self.f1(out))\n",
    "        out = F.relu(self.f2(out))\n",
    "        out = self.f3(out)\n",
    "        # print(out.size())\n",
    "        \n",
    "        probs = F.softmax(out, dim=1)\n",
    "        # print(probs)\n",
    "        classes = torch.max(probs, 1)[1]\n",
    "\n",
    "        return probs, classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2018-11-26 14:57:06,862\t==================== Epoch: 1 ====================\n",
      "INFO\t2018-11-26 14:57:17,450\tstep = 0, loss = 0.6983174681663513\n",
      "INFO\t2018-11-26 14:57:26,453\tstep = 100, loss = 0.6350847744941711\n",
      "INFO\t2018-11-26 14:57:35,162\tstep = 200, loss = 0.597502669095993\n",
      "INFO\t2018-11-26 14:57:43,285\tstep = 300, loss = 0.5649592766165733\n",
      "INFO\t2018-11-26 14:57:52,235\tstep = 400, loss = 0.5579814839363099\n",
      "INFO\t2018-11-26 14:58:01,308\tstep = 500, loss = 0.5507378333806991\n",
      "INFO\t2018-11-26 14:58:09,753\tstep = 600, loss = 0.5403113803267479\n",
      "INFO\t2018-11-26 14:58:19,162\tstep = 700, loss = 0.5407187908887863\n",
      "INFO\t2018-11-26 14:58:27,946\tstep = 800, loss = 0.5406585448980331\n",
      "INFO\t2018-11-26 14:58:37,447\tstep = 900, loss = 0.5351702859997749\n",
      "INFO\t2018-11-26 14:58:45,922\t==================== Epoch: 2 ====================\n",
      "INFO\t2018-11-26 14:58:55,914\tstep = 1000, loss = 0.5216349363327026\n",
      "INFO\t2018-11-26 14:59:05,571\tstep = 1100, loss = 0.5293188491463661\n",
      "INFO\t2018-11-26 14:59:13,462\tstep = 1200, loss = 0.530385116636753\n",
      "INFO\t2018-11-26 14:59:21,898\tstep = 1300, loss = 0.5276104468107223\n",
      "INFO\t2018-11-26 14:59:30,756\tstep = 1400, loss = 0.5211469012498856\n",
      "INFO\t2018-11-26 14:59:39,508\tstep = 1500, loss = 0.522524006664753\n",
      "INFO\t2018-11-26 14:59:48,725\tstep = 1600, loss = 0.5190884602069855\n",
      "INFO\t2018-11-26 14:59:57,443\tstep = 1700, loss = 0.5148154050111771\n",
      "INFO\t2018-11-26 15:00:06,220\tstep = 1800, loss = 0.5169826143980026\n",
      "INFO\t2018-11-26 15:00:14,466\tstep = 1900, loss = 0.513673465847969\n",
      "INFO\t2018-11-26 15:00:21,053\t==================== Epoch: 3 ====================\n",
      "INFO\t2018-11-26 15:00:30,686\tstep = 2000, loss = 0.5146890878677368\n",
      "INFO\t2018-11-26 15:00:36,905\tstep = 2100, loss = 0.5096891662478447\n",
      "INFO\t2018-11-26 15:00:43,481\tstep = 2200, loss = 0.5130128082633019\n",
      "INFO\t2018-11-26 15:00:49,456\tstep = 2300, loss = 0.5102364709973335\n",
      "INFO\t2018-11-26 15:00:55,975\tstep = 2400, loss = 0.5051740574836731\n",
      "INFO\t2018-11-26 15:01:02,020\tstep = 2500, loss = 0.509531392455101\n",
      "INFO\t2018-11-26 15:01:08,386\tstep = 2600, loss = 0.5037005341053009\n",
      "INFO\t2018-11-26 15:01:14,336\tstep = 2700, loss = 0.4999333289265633\n",
      "INFO\t2018-11-26 15:01:20,297\tstep = 2800, loss = 0.50387824177742\n",
      "INFO\t2018-11-26 15:01:26,763\tstep = 2900, loss = 0.49937106400728226\n",
      "INFO\t2018-11-26 15:01:32,970\t==================== Epoch: 4 ====================\n",
      "INFO\t2018-11-26 15:01:42,805\tstep = 3000, loss = 0.5161094665527344\n",
      "INFO\t2018-11-26 15:01:49,931\tstep = 3100, loss = 0.49595130145549776\n",
      "INFO\t2018-11-26 15:01:56,011\tstep = 3200, loss = 0.5016098067164421\n",
      "INFO\t2018-11-26 15:02:02,233\tstep = 3300, loss = 0.4968665635585785\n",
      "INFO\t2018-11-26 15:02:08,963\tstep = 3400, loss = 0.49165069103240966\n",
      "INFO\t2018-11-26 15:02:15,427\tstep = 3500, loss = 0.4996795624494553\n",
      "INFO\t2018-11-26 15:02:22,326\tstep = 3600, loss = 0.49209653347730636\n",
      "INFO\t2018-11-26 15:02:28,484\tstep = 3700, loss = 0.48825209856033325\n",
      "INFO\t2018-11-26 15:02:35,395\tstep = 3800, loss = 0.48880491584539415\n",
      "INFO\t2018-11-26 15:02:42,531\tstep = 3900, loss = 0.4881941705942154\n",
      "INFO\t2018-11-26 15:02:49,052\t==================== Epoch: 5 ====================\n",
      "INFO\t2018-11-26 15:02:59,086\tstep = 4000, loss = 0.511238157749176\n",
      "INFO\t2018-11-26 15:03:05,032\tstep = 4100, loss = 0.48705714851617815\n",
      "INFO\t2018-11-26 15:03:11,927\tstep = 4200, loss = 0.4936822348833084\n",
      "INFO\t2018-11-26 15:03:18,215\tstep = 4300, loss = 0.48636587589979174\n",
      "INFO\t2018-11-26 15:03:25,186\tstep = 4400, loss = 0.48086476534605027\n",
      "INFO\t2018-11-26 15:03:31,865\tstep = 4500, loss = 0.48963952690362933\n",
      "INFO\t2018-11-26 15:03:39,641\tstep = 4600, loss = 0.48604269593954086\n",
      "INFO\t2018-11-26 15:03:46,203\tstep = 4700, loss = 0.4845735839009285\n",
      "INFO\t2018-11-26 15:03:52,554\tstep = 4800, loss = 0.48106851369142534\n",
      "INFO\t2018-11-26 15:03:58,769\tstep = 4900, loss = 0.48256172358989713\n",
      "INFO\t2018-11-26 15:04:04,627\t==================== Epoch: 6 ====================\n",
      "INFO\t2018-11-26 15:04:14,379\tstep = 5000, loss = 0.49344301223754883\n",
      "INFO\t2018-11-26 15:04:20,428\tstep = 5100, loss = 0.47914204865694043\n",
      "INFO\t2018-11-26 15:04:26,643\tstep = 5200, loss = 0.4835005137324333\n",
      "INFO\t2018-11-26 15:04:32,952\tstep = 5300, loss = 0.47795574426651\n",
      "INFO\t2018-11-26 15:04:38,944\tstep = 5400, loss = 0.4727840059995651\n",
      "INFO\t2018-11-26 15:04:44,844\tstep = 5500, loss = 0.4824194288253784\n",
      "INFO\t2018-11-26 15:04:51,015\tstep = 5600, loss = 0.4821239933371544\n",
      "INFO\t2018-11-26 15:04:58,746\tstep = 5700, loss = 0.4792711842060089\n",
      "INFO\t2018-11-26 15:05:05,687\tstep = 5800, loss = 0.4744479802250862\n",
      "INFO\t2018-11-26 15:05:12,578\tstep = 5900, loss = 0.47808591842651366\n",
      "INFO\t2018-11-26 15:05:18,742\t==================== Epoch: 7 ====================\n",
      "INFO\t2018-11-26 15:05:28,452\tstep = 6000, loss = 0.4861578941345215\n",
      "INFO\t2018-11-26 15:05:34,874\tstep = 6100, loss = 0.4713489279150963\n",
      "INFO\t2018-11-26 15:05:41,481\tstep = 6200, loss = 0.4731662970781326\n",
      "INFO\t2018-11-26 15:05:48,317\tstep = 6300, loss = 0.46680317640304564\n",
      "INFO\t2018-11-26 15:05:55,237\tstep = 6400, loss = 0.46892297625541685\n",
      "INFO\t2018-11-26 15:06:01,753\tstep = 6500, loss = 0.47519043445587156\n",
      "INFO\t2018-11-26 15:06:07,979\tstep = 6600, loss = 0.4733186861872673\n",
      "INFO\t2018-11-26 15:06:14,505\tstep = 6700, loss = 0.4714537239074707\n",
      "INFO\t2018-11-26 15:06:20,680\tstep = 6800, loss = 0.4746720317006111\n",
      "INFO\t2018-11-26 15:06:27,077\tstep = 6900, loss = 0.4713493898510933\n",
      "INFO\t2018-11-26 15:06:33,494\t==================== Epoch: 8 ====================\n",
      "INFO\t2018-11-26 15:06:43,236\tstep = 7000, loss = 0.45212146639823914\n",
      "INFO\t2018-11-26 15:06:50,111\tstep = 7100, loss = 0.46678319841623306\n",
      "INFO\t2018-11-26 15:06:56,458\tstep = 7200, loss = 0.46959918320178984\n",
      "INFO\t2018-11-26 15:07:03,073\tstep = 7300, loss = 0.466367110311985\n",
      "INFO\t2018-11-26 15:07:10,119\tstep = 7400, loss = 0.46282613307237624\n",
      "INFO\t2018-11-26 15:07:16,737\tstep = 7500, loss = 0.47013229042291643\n",
      "INFO\t2018-11-26 15:07:22,862\tstep = 7600, loss = 0.4655244132876396\n",
      "INFO\t2018-11-26 15:07:29,172\tstep = 7700, loss = 0.46182041853666306\n",
      "INFO\t2018-11-26 15:07:37,145\tstep = 7800, loss = 0.48184089601039887\n",
      "INFO\t2018-11-26 15:07:43,473\tstep = 7900, loss = 0.46856894373893737\n",
      "INFO\t2018-11-26 15:07:50,220\t==================== Epoch: 9 ====================\n",
      "INFO\t2018-11-26 15:08:00,275\tstep = 8000, loss = 0.46363410353660583\n",
      "INFO\t2018-11-26 15:08:06,705\tstep = 8100, loss = 0.45481770247220993\n",
      "INFO\t2018-11-26 15:08:13,133\tstep = 8200, loss = 0.46232037991285324\n",
      "INFO\t2018-11-26 15:08:20,144\tstep = 8300, loss = 0.45421765476465226\n",
      "INFO\t2018-11-26 15:08:26,706\tstep = 8400, loss = 0.4588025039434433\n",
      "INFO\t2018-11-26 15:08:33,642\tstep = 8500, loss = 0.45997523635625837\n",
      "INFO\t2018-11-26 15:08:40,260\tstep = 8600, loss = 0.46474158108234404\n",
      "INFO\t2018-11-26 15:08:46,868\tstep = 8700, loss = 0.4533429428935051\n",
      "INFO\t2018-11-26 15:08:53,046\tstep = 8800, loss = 0.46995409548282624\n",
      "INFO\t2018-11-26 15:08:59,806\tstep = 8900, loss = 0.4595195487141609\n",
      "INFO\t2018-11-26 15:09:06,570\t==================== Epoch: 10 ====================\n",
      "INFO\t2018-11-26 15:09:16,452\tstep = 9000, loss = 0.44414788484573364\n",
      "INFO\t2018-11-26 15:09:23,048\tstep = 9100, loss = 0.45146427154541013\n",
      "INFO\t2018-11-26 15:09:29,611\tstep = 9200, loss = 0.4557021591067314\n",
      "INFO\t2018-11-26 15:09:35,956\tstep = 9300, loss = 0.45142183601856234\n",
      "INFO\t2018-11-26 15:09:42,263\tstep = 9400, loss = 0.45943156391382217\n",
      "INFO\t2018-11-26 15:09:48,843\tstep = 9500, loss = 0.4547348502278328\n",
      "INFO\t2018-11-26 15:09:56,168\tstep = 9600, loss = 0.46363860070705415\n",
      "INFO\t2018-11-26 15:10:02,324\tstep = 9700, loss = 0.4528062719106674\n",
      "INFO\t2018-11-26 15:10:09,123\tstep = 9800, loss = 0.46374494194984434\n",
      "INFO\t2018-11-26 15:10:15,927\tstep = 9900, loss = 0.460321888923645\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format=\"%(levelname)s\\t%(asctime)s\\t%(message)s\", level=logging.INFO)\n",
    "import logging\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=\"log\")\n",
    "\n",
    "\n",
    "    epoch = 0\n",
    "    step = 0\n",
    "\n",
    "\n",
    "    for epoch in range(1, config.num_epochs + 1):\n",
    "        logging.info(\"==================== Epoch: {} ====================\".format(epoch))\n",
    "        running_losses = []\n",
    "        for batch in train_set:\n",
    "\n",
    "            sequences = torch.Tensor(batch[\"sequences\"])\n",
    "            labels = torch.LongTensor(batch[\"labels\"])\n",
    "\n",
    "            # Predict\n",
    "            probs, classes = model(sequences)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            losses = loss_function(probs, labels)\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log summary\n",
    "            running_losses.append(losses.data.item())\n",
    "            if step % config.summary_interval == 0:\n",
    "                loss = sum(running_losses) / len(running_losses)\n",
    "                writer.add_scalar(\"train/loss\", loss, step)\n",
    "                logging.info(\"step = {}, loss = {}\".format(step, loss))\n",
    "                running_losses = []\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        epoch += 1\n",
    "        \n",
    "model = CNNClassifier()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
