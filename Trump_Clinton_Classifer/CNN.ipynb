{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量化（vectorize）\n",
    "\n",
    "# from my_weapon import *\n",
    "from gensim.models import Word2Vec\n",
    "import word2vecReader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.425314e+06\n",
      "mean     1.650435e+01\n",
      "std      5.510423e+00\n",
      "min      1.000000e+00\n",
      "25%      1.300000e+01\n",
      "50%      1.700000e+01\n",
      "75%      2.000000e+01\n",
      "max      1.110000e+02\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 统计最长的序列\n",
    "\n",
    "d = pd.Series([len(line.strip().split(\" \")) for line in open(\"data/train.txt\")])\n",
    "print(d.describe())\n",
    "d.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2Vec.load(\"model/word2vec.mod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最长的序列是111个tokens，我决定用40作为每个句子的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update vectorize\n",
    "# 需要经过tweet_process.py的处理\n",
    "\n",
    "def vectorize(line):\n",
    "    v = np.zeros(40 * 400).reshape(40, 400)\n",
    "    words = line.strip().split(\" \")\n",
    "    _index = 0\n",
    "    for w in words:\n",
    "        if _index >= 40:\n",
    "            break\n",
    "        if w in wv_model.wv:\n",
    "            v[_index] = wv_model.wv[w]\n",
    "            _index += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.08587575,  0.41580471, -2.2741425 , ..., -0.0125636 ,\n",
       "         2.06250668,  0.08311198],\n",
       "       [-0.81667441,  0.94962615, -1.45155382, ...,  0.22324868,\n",
       "         1.16281199, -0.71577537],\n",
       "       [-0.68626755,  0.78144592, -2.61305523, ...,  0.71367294,\n",
       "         0.76811117,  2.10258842],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(\"what are you doing ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们看看另外一个已经训练好的在大的数据集上的word2vec model\n",
    "\n",
    "location: /media/alex/data/word2vec_twitter_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\tword2vecReader.py  word2vecReaderUtils.py  word2vec_twitter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls /media/alex/data/word2vec_twitter_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This zip contains a word2vec model trained on Twitter data as described in:\n",
      "\n",
      "Godin, F., Vandersmissen, B., De Neve, W., & Van de Walle, R. (2015).\n",
      "Multimedia Lab @ ACL W-NUT NER shared task: Named entity recognition for Twitter microposts using distributed word representations.\n",
      "Workshop on Noisy User-generated Text, ACL 2015.\n",
      "\n",
      "Please cite the paper if you use the model.\n",
      "\n",
      "This zip contains 2 additional files to read the word2vec model with Python.\n",
      "The code for this was extracted from the Gensim Library which can be found here: https://radimrehurek.com/gensim/models/word2vec.html\n",
      "The only difference is that it does not use a strict encoding to read the model from the file.\n",
      "(One can easily integrate, inherit or extend the library or the Python files)"
     ]
    }
   ],
   "source": [
    "!cat /media/alex/data/word2vec_twitter_model/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model2 = word2vecReader.Word2Vec.load_word2vec_format(\"/media/alex/data/word2vec_twitter_model/word2vec_twitter_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model2[\"love\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_2(line):\n",
    "    v = np.zeros(40 * 400).reshape(40, 400)\n",
    "    words = line.strip().split(\" \")\n",
    "    _index = 0\n",
    "    for w in words:\n",
    "        if _index >= 40:\n",
    "            break\n",
    "        if w in wv_model2:\n",
    "            v[_index] = wv_model2[w]\n",
    "            _index += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03832966,  0.00200333, -0.04462779, ...,  0.0044597 ,\n",
       "         0.02114136, -0.02238772],\n",
       "       [ 0.04128342,  0.07181156,  0.00676483, ..., -0.00052616,\n",
       "         0.01673744,  0.01691386],\n",
       "       [-0.01901733,  0.00757742,  0.00171131, ...,  0.05948232,\n",
       "         0.0217214 , -0.00660098],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_2(\"i love you so much\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([128, 64, 98, 1])\n",
      "relu: torch.Size([128, 64, 98, 1])\n",
      "squeeze: torch.Size([128, 64, 98])\n",
      "max_pool1d: torch.Size([128, 64, 49])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1216]' is invalid for input of size 401408",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-350c7ee7f407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_pool1d:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0m_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flat:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1216]' is invalid for input of size 401408"
     ]
    }
   ],
   "source": [
    "# batch=128, in_channels=2, height(num of tokens)=100, width(length of word2vec)=400\n",
    "_in = torch.randn(128, 2, 100, 400)\n",
    "\n",
    "# in_channels=2, out_channels=32, kernel_size=(3, 400)\n",
    "tmp_mod = torch.nn.Conv2d(2, 64, kernel_size=(3, 400), groups=2)\n",
    "\n",
    "_out = tmp_mod(_in)\n",
    "print(\"conv1:\", _out.size())\n",
    "\n",
    "_out = F.relu(_out)\n",
    "print(\"relu:\", _out.size())\n",
    "\n",
    "_out = torch.squeeze(_out)\n",
    "print(\"squeeze:\", _out.size())\n",
    "\n",
    "_out = F.max_pool1d(_out, 2)\n",
    "print(\"max_pool1d:\", _out.size())\n",
    "\n",
    "_out = _out.view(-1, 2 * 32 * 19)\n",
    "print(\"flat:\", _out.size())\n",
    "\n",
    "f1 = nn.Linear(1216, 64)\n",
    "_out = f1(_out)\n",
    "_out = F.relu(_out)\n",
    "print(\"f1:\", _out.size())\n",
    "\n",
    "f2 = nn.Linear(64, 32)\n",
    "_out = f2(_out)\n",
    "_out = F.relu(_out)\n",
    "print(\"f2:\", _out.size())\n",
    "\n",
    "f3 = nn.Linear(32, 1)\n",
    "_out = f3(_out)\n",
    "# _out = F.relu(_out)\n",
    "print(\"f3:\", _out.size())\n",
    "\n",
    "probs = F.softmax(_out, 1)\n",
    "print(probs)\n",
    "torch.max(probs, 1)[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train dataset\n",
    "\n",
    "import random\n",
    "\n",
    "with open(\"data/train_dataset.txt\", \"w\") as f:\n",
    "    lines = []\n",
    "    for line in open(\"data/0-train.txt\"):\n",
    "        lines.append(\"0\\t{}\".format(line))\n",
    "    for line in open(\"data/1-train.txt\"):\n",
    "        lines.append(\"1\\t{}\".format(line))\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.train_file = \"data/train_dataset.txt\"\n",
    "        self.train_batch_size = 128\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        self.window_size = 3\n",
    "        self.num_classes = 2\n",
    "        \n",
    "        self.num_epochs = 10\n",
    "        self.train_steps = None\n",
    "        \n",
    "        self.summary_interval = 100\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10 条信息，2 Input，40 词，每个词400向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wv1 ...\n",
      "CPU times: user 1.22 s, sys: 720 ms, total: 1.94 s\n",
      "Wall time: 4.33 s\n",
      "Loading wv2 ...\n",
      "CPU times: user 44.1 s, sys: 3.02 s, total: 47.1 s\n",
      "Wall time: 47.2 s\n"
     ]
    }
   ],
   "source": [
    "def read_wv1():\n",
    "    print(\"Loading wv1 ...\")\n",
    "    return Word2Vec.load(\"model/word2vec.mod\")\n",
    "        \n",
    "def read_wv2():\n",
    "    print(\"Loading wv2 ...\")\n",
    "    return word2vecReader.Word2Vec.load_word2vec_format(\n",
    "        \"/media/alex/data/word2vec_twitter_model/word2vec_twitter_model.bin\", binary=True)\n",
    "    \n",
    "%time _wv1 = read_wv1()\n",
    "%time _wv2 = read_wv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, filepath, batch_size):\n",
    "        self._file = open(filepath)\n",
    "#         self._wv1 = _wv1\n",
    "#         self._wv2 = _wv2\n",
    "        self._batch_size = batch_size\n",
    "        self._reset()\n",
    "        \n",
    "#     def wv1(self, line):\n",
    "#         v = np.zeros(40 * 400).reshape(40, 400)\n",
    "#         words = line.strip().split(\" \")\n",
    "#         _index = 0\n",
    "#         for w in words:\n",
    "#             if _index >= 40:\n",
    "#                 break\n",
    "#             if w in self._wv1.wv:\n",
    "#                 v[_index] = self._wv1.wv[w]\n",
    "#                 _index += 1\n",
    "#         return v\n",
    "\n",
    "#     def wv2(self, line):\n",
    "#             v = np.zeros(40 * 400).reshape(40, 400)\n",
    "#             words = line.strip().split(\" \")\n",
    "#             _index = 0\n",
    "#             for w in words:\n",
    "#                 if _index >= 40:\n",
    "#                     break\n",
    "#                 if w in self._wv2:\n",
    "#                     v[_index] = self._wv2[w]\n",
    "#                     _index += 1\n",
    "#             return v\n",
    "\n",
    "    # 迭代时候每次先调用__iter__，初始化\n",
    "    # 接着调用__next__返回数据\n",
    "    # 如果没有buffer的时候，就补充数据_fill_buffer\n",
    "    # 如果buffer补充后仍然为空，则停止迭代\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._reset()\n",
    "        return self\n",
    "    \n",
    "    def _fill_buffer(self, size):\n",
    "        global cnt\n",
    "\n",
    "        if self._buff_count < self._batch_size:\n",
    "            print(\"buffer空了，补充数据 ...\")\n",
    "            for line in self._file:\n",
    "                try:\n",
    "                    label, sentence = line.strip().split(\"\\t\")\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                label = int(label.strip())\n",
    "                # sequence1 = self.wv1(sentence)\n",
    "                # sequence2 = self.wv2(sentence)\n",
    "                \n",
    "                sequence1 = np.zeros(40 * 400).reshape(40, 400)\n",
    "                sequence2 = np.zeros(40 * 400).reshape(40, 400)\n",
    "                \n",
    "                self._buff_count += 1\n",
    "                self._buffer.append((label, [sequence1, sequence2]))\n",
    "                ## 直到满足size\n",
    "                \n",
    "                if self._buff_count >= size:\n",
    "                    break\n",
    "                    \n",
    "                cnt += 1\n",
    "                if cnt % 50000 == 0:\n",
    "                    print(cnt)\n",
    "            self._buffer_iter = iter(self._buffer)\n",
    "    \n",
    "    def __next__(self):\n",
    "        self._fill_buffer(self._batch_size * 1000) # 每次读1024个batch作为buffer\n",
    "        \n",
    "        if self._buff_count == 0: # After filling, still empty, stop iter!\n",
    "            raise StopIteration\n",
    "                \n",
    "        # global cnt\n",
    "        label_batch = []\n",
    "        sequence_batch = []\n",
    "        for label, sequence in self._buffer_iter:\n",
    "            self._buff_count -= 1\n",
    "            label_batch.append(label)\n",
    "            sequence_batch.append(sequence)\n",
    "            if len(label_batch) == self._batch_size:\n",
    "                break\n",
    "\n",
    "\n",
    "        return {\"sequences\": np.array(sequence_batch), \"labels\": label_batch, }\n",
    "\n",
    "    def _reset(self):\n",
    "        self._file.seek(0)\n",
    "        self._buffer = []\n",
    "        self._buffer_iter = None\n",
    "        self._buff_count = 0\n",
    "        \n",
    "    def get_testdata(self):\n",
    "        labels = []\n",
    "        sequences = []\n",
    "        for line in open(\"data/0-test.txt\"):\n",
    "            labels.append(0)\n",
    "            sequences.append([self.wv1(line), self.wv2(line)])\n",
    "        for line in open(\"data/1-test.txt\"):\n",
    "            labels.append(1)\n",
    "            sequences.append([self.wv1(line), self.wv2(line)])\n",
    "        return torch.LongTensor(labels), torch.Tensor(sequences)\n",
    "\n",
    "    \n",
    "train_set = Dataset(config.train_file, config.train_batch_size)\n",
    "# %time test_labels, test_X = train_set.get_testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer空了，补充数据 ...\n",
      "50000\n",
      "100000\n",
      "0 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "500 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "buffer空了，补充数据 ...\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "1000 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "1500 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "buffer空了，补充数据 ...\n",
      "300000\n",
      "350000\n",
      "2000 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "2500 torch.Size([128, 2, 40, 400]) torch.Size([128])\n",
      "buffer空了，补充数据 ...\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_set):\n",
    "    if i % 500 == 0:\n",
    "        sequences = torch.Tensor(batch[\"sequences\"])\n",
    "        labels = torch.LongTensor(batch[\"labels\"])\n",
    "        print(i, sequences.size(), labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        # 2 in- channels, 32 out- channels, 3 * 400 windows size\n",
    "        self.conv = torch.nn.Conv2d(2, 64, kernel_size=(3, 400), groups=2) \n",
    "        self.f1 = nn.Linear(1216, 64)\n",
    "        self.f2 = nn.Linear(64, 32)\n",
    "        self.f3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = F.relu(out)\n",
    "        out = torch.squeeze(out)\n",
    "        out = F.max_pool1d(out, 2)\n",
    "        out = out.view(-1, 2 * 32 * 19) # 9 is after pooling\n",
    "        out = F.relu(self.f1(out))\n",
    "        out = F.relu(self.f2(out))\n",
    "        out = self.f3(out)\n",
    "        # print(out.size())\n",
    "        \n",
    "        probs = F.softmax(out, dim=1)\n",
    "        # print(probs)\n",
    "        classes = torch.max(probs, 1)[1]\n",
    "\n",
    "        return probs, classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2018-11-26 19:14:19,993\t==================== Epoch: 1 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer空了，补充数据 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2018-11-26 19:14:29,585\tstep = 0, loss = 0.7093743681907654\n",
      "INFO\t2018-11-26 19:14:37,474\tstep = 100, loss = 0.6470441317558289\n",
      "INFO\t2018-11-26 19:14:43,797\tstep = 200, loss = 0.6051749521493912\n",
      "INFO\t2018-11-26 19:14:50,283\tstep = 300, loss = 0.5732173711061478\n",
      "INFO\t2018-11-26 19:14:56,350\tstep = 400, loss = 0.558872994184494\n",
      "INFO\t2018-11-26 19:15:03,328\tstep = 500, loss = 0.5485111489892006\n",
      "INFO\t2018-11-26 19:15:09,534\tstep = 600, loss = 0.5401800882816314\n",
      "INFO\t2018-11-26 19:15:16,229\tstep = 700, loss = 0.5370687690377235\n",
      "INFO\t2018-11-26 19:15:22,392\tstep = 800, loss = 0.5362289342284202\n",
      "INFO\t2018-11-26 19:15:28,223\tstep = 900, loss = 0.5305288290977478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer空了，补充数据 ...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s\\t%(asctime)s\\t%(message)s\", level=logging.INFO)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=\"log\")\n",
    "    \n",
    "    epoch = 0\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(1, config.num_epochs + 1):\n",
    "        logging.info(\"==================== Epoch: {} ====================\".format(epoch))\n",
    "        running_losses = []\n",
    "        for batch in train_set:\n",
    "\n",
    "            sequences = torch.Tensor(batch[\"sequences\"])\n",
    "            labels = torch.LongTensor(batch[\"labels\"])\n",
    "\n",
    "            # Predict\n",
    "            try:\n",
    "                probs, classes = model(sequences)\n",
    "            except:\n",
    "                print(sequences.size(), labels.size())\n",
    "                exit(-1)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            losses = loss_function(probs, labels)\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log summary\n",
    "            running_losses.append(losses.data.item())\n",
    "            if step % config.summary_interval == 0:\n",
    "                loss = sum(running_losses) / len(running_losses)\n",
    "                writer.add_scalar(\"train/loss\", loss, step)\n",
    "                logging.info(\"step = {}, loss = {}\".format(step, loss))\n",
    "                running_losses = []\n",
    "            \n",
    "            step += 1\n",
    "        \n",
    "        # Classification report\n",
    "        probs, y_pred = model(test_X)\n",
    "        target_names = ['pro-hillary', 'pro-trump']\n",
    "        print(classification_report(test_labels, y_pred, target_names=target_names))\n",
    "\n",
    "        epoch += 1\n",
    "        \n",
    "model = CNNClassifier()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
